{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thermal Conductivity Fit Analysis\n",
    "Developed by Henry Nachman\n",
    "\n",
    "Last Edited: 22 February 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# note : most functions needed for running this notebook can be found in tc_utils.\n",
    "from tc_utils import *\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to find where all our RAW data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aluminum': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\Aluminum\\\\RAW', 'CFRP': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\CFRP\\\\RAW', 'Clearwater': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\Clearwater\\\\RAW', 'DPP': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\DPP\\\\RAW', 'Fiberglass': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\Fiberglass\\\\RAW', 'Graphlite': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\Graphlite\\\\RAW', 'Ketron': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\Ketron\\\\RAW', 'Macor': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\Macor\\\\RAW', 'POCO Graphite': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\POCO Graphite\\\\RAW', 'SS304': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\SS304\\\\RAW', 'Torlon': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\Torlon\\\\RAW', 'VESPEL': 'c:\\\\Users\\\\henac\\\\OneDrive - The University of Texas at Austin\\\\01_RESEARCH\\\\05_CMBS4\\\\Cryogenic_Material_Properties\\\\thermal_conductivity\\\\lib\\\\VESPEL\\\\RAW'}\n"
     ]
    }
   ],
   "source": [
    "path_to_lib = f\"{os.getcwd()}\\\\lib\"\n",
    "mat_directories = [folder for folder in os.listdir(path_to_lib) if not folder.endswith(\".md\")]\n",
    "\n",
    "path_to_RAW = dict()\n",
    "path_to_fits = dict()\n",
    "\n",
    "for mat in mat_directories:\n",
    "    raw_str = f\"{path_to_lib}\\\\{mat}\\\\RAW\"\n",
    "    if os.path.exists(raw_str):\n",
    "        path_to_RAW[mat] = raw_str\n",
    "    path_to_fits[mat] = raw_str\n",
    "\n",
    "print(path_to_RAW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our fitting code for every material found in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a low fit - 1.061 is below 20K.\n",
      "\n",
      "Using a low fit - 4.842 is below 20K.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Using a low fit - 4.842 is below 20K.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Using a low fit - 4.02 is below 20K.\n",
      "\n",
      "\n",
      "Using a low fit - 2.970783932 is below 20K.\n",
      "\n",
      "Using a low fit - 4.015 is below 20K.\n",
      "\n",
      "\n",
      "Using a low fit - 2.851 is below 20K.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henac\\OneDrive - The University of Texas at Austin\\01_RESEARCH\\05_CMBS4\\Cryogenic_Material_Properties\\thermal_conductivity\\tc_utils.py:477: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, axs = plt.subplots(2, figsize=(8, 6))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using a low fit - 3.21338073 is below 20K.\n",
      "\n",
      "Using a low fit - 3.245 is below 20K.\n",
      "\n",
      "Using a combined fit - data exists on both sides of 20K.\n",
      "Only using high fit minT: 0.3846 > 20\n",
      "Only using low fit 1672.0 < 20\n",
      "Low-Hi split centered at : 119.7857 ~~ with average percent difference value of: 3.95%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Using a low fit - 2.977 is below 20K.\n",
      "\n",
      "Using a low fit - 3.032 is below 20K.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mat in path_to_RAW.keys(): # [\"SS304\"]: # \n",
    "    perc_diff_avg = np.array([])\n",
    "    ## First, let's collect the raw data from their csv files\n",
    "    big_data, data_dict = parse_raw(mat, path_to_RAW[mat], plots=False, weight_const=0.00)\n",
    "    T, k, koT, weights = [big_data[:,0], big_data[:,1], big_data[:,2], big_data[:,3]]\n",
    "\n",
    "    maxT, minT = [max(T), min(T)]\n",
    "    fit_orders = [3,3]\n",
    "    fit_types = [\"k/T\", \"loglog\"]\n",
    "\n",
    "    if (maxT <= 20):\n",
    "        print(f\"Using a low fit - {maxT} is below 20K.\")\n",
    "        low_fit_xs, low_fit = koT_function(T, koT, fit_orders[0], weights)\n",
    "        hi_fit, hi_fit_xs, erf_loc = [[0], [0], [0]]\n",
    "        fit_args = dict_combofit(low_fit, low_fit_xs, hi_fit, hi_fit_xs, fit_orders, fit_types, erf_loc)\n",
    "    elif (minT >= 20):\n",
    "        print(f\"Using a hi fit - {minT} is above 20K.\")\n",
    "        hi_fit_xs, hi_fit = logk_function(np.log10(T), np.log10(k), fit_orders[1], weights)\n",
    "        low_fit, low_fit_xs, erf_loc = [[0], [0], [-1]]\n",
    "        fit_args = dict_combofit(low_fit, low_fit_xs, hi_fit, hi_fit_xs, fit_orders, fit_types, erf_loc)\n",
    "    else:\n",
    "        print(f\"Using a combined fit - data exists on both sides of 20K.\")\n",
    "        erf_locList = np.linspace(np.sort(T)[0], np.sort(T)[-1], 15) # [30] # \n",
    "        for erf_loc in erf_locList:\n",
    "            dsplit = split_data(big_data, erf_loc)\n",
    "            lowT, lowT_k, lowT_koT, low_ws, hiT, hiT_k, hiT_koT, hi_ws = dsplit\n",
    "            # Take a log10 of the high range\n",
    "            log_hi_T = np.log10(hiT)\n",
    "            log_hi_k = np.log10(hiT_k)\n",
    "            \n",
    "            if (len(lowT)==0):\n",
    "                low_fit = [0]\n",
    "                print(f\"Only using high fit minT: {min(T)} > 20\")\n",
    "            else:\n",
    "                low_fit_xs, low_fit = koT_function(lowT, lowT_koT, fit_orders[0], low_ws)\n",
    "            if (len(hiT)==0):\n",
    "                hi_fit = [0]\n",
    "                print(f\"Only using low fit {max(T)} < 20\")\n",
    "            else:\n",
    "                hi_fit_xs, hi_fit = logk_function(log_hi_T, log_hi_k, fit_orders[1], hi_ws)\n",
    "            fit_args = dict_combofit(low_fit, low_fit_xs, hi_fit, hi_fit_xs, fit_orders, fit_types, erf_loc)\n",
    "            ## With the fit complete, let's output a formatted dictionary with the fit parameters\n",
    "            output_array = format_combofit(fit_args)\n",
    "            ## We want to figure out the best location for the split in data, so we will compute the residual of the combined fit\n",
    "            # Tdata = np.concatenate([(data_dict[ref_name].T[0]) for ref_name in data_dict])\n",
    "            # kdata = np.concatenate([(data_dict[ref_name].T[1]) for ref_name in data_dict])\n",
    "            low_param, hi_param, erf_param = fit_args[\"low_fit_param\"], fit_args[\"hi_fit_param\"], fit_args[\"combined_fit_param\"][-1]\n",
    "            kpred = loglog_func(T, low_param, hi_param, erf_param)\n",
    "            # and append it to the array resVal\n",
    "            diff = abs(kpred-k)\n",
    "            perc_diff_arr = 100*diff/kpred\n",
    "            # print((kpred-kpred*perc_diff_arr)[Tdata.argsort()])\n",
    "            perc_diff_avg = np.append(perc_diff_avg, np.mean(perc_diff_arr))\n",
    "\n",
    "        # plt.plot(erf_locList, perc_diff_avg)\n",
    "        # plt.show()\n",
    "        # Now that we have found the residuals of the fits for many different split locations, let's choose the best one.    \n",
    "        erf_locdict = dict(zip(erf_locList, perc_diff_avg))\n",
    "        bestRes = min(erf_locdict.values())\n",
    "        besterf_loc = [key for key in erf_locdict if erf_locdict[key] == bestRes]\n",
    "        print(f\"Low-Hi split centered at : {besterf_loc[0]} ~~ with average percent difference value of: {bestRes:.2f}%\")\n",
    "        \n",
    "        # We will repeat the above fit with this new 'optimized' split location\n",
    "        fit_args = dual_tc_fit(big_data, os.path.split(path_to_RAW[mat])[0], erf_loc=besterf_loc, fit_orders=(3, 3), plots=False)\n",
    "    \n",
    "    output_array = format_combofit(fit_args)\n",
    "\n",
    "    # Finally, we will output the fit parameters as a csv, and lh5 file - and plot the data.\n",
    "    create_data_table(output_array, f\"{os.path.split(path_to_RAW[mat])[0]}\\\\{os.path.split(os.path.split(path_to_RAW[mat])[0])[1]}.txt\")\n",
    "    create_tc_csv(output_array, f\"{os.path.split(path_to_RAW[mat])[0]}\\\\{os.path.split(os.path.split(path_to_RAW[mat])[0])[1]}.csv\")\n",
    "    make_fit_lh5(fit_args, os.path.split(path_to_RAW[mat])[0])\n",
    "    # PLOTTING CODE\n",
    "    tk_plot(mat,path_to_RAW, data_dict, fit_args, fit_range = [100e-3, np.sort(T)[-1]], points=True, fits=\"combined\", fill=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets output a single human readable (and CSV) file of the fits for each material currently in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_array = compile_csv(path_to_fits)\n",
    "create_data_table(output_array, \"..\\\\thermal_conductivity_compilation.txt\")\n",
    "create_tc_csv(output_array, \"..\\\\thermal_conductivity_compilation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENAPenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
